{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxizCYr2DYCMHeKYLcNdKm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suriarasai/BEAD2024/blob/main/colab/Introduction_to_Python_and_PySpark_on_CoLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This workshop walks through google CoLab sandbox. Google Colab is an online platform provided by Google that allows users to write and execute Python code through the browser. It's especially popular for machine learning and data analysis projects because it offers free access to certain computing resources, including GPUs and TPUs, which can significantly speed up processing times.\n",
        "\n",
        "Colab notebooks are interactive documents, like Jupyter Notebooks (a flexible web-based interactive development environment for notebooks, code, and data.). They allow you to combine executable code, rich text, images, and other multimedia in a single document. Colab comes with pre-installed Python libraries for data analysis and visualization, such as NumPy, Pandas, Matplotlib, and Seaborn.\n",
        "\n",
        "Colab is integrated with Google Drive, making it easy to share work, access various file types, and collaborate with others. It's widely used for educational purposes, as well as for research and development in various scientific disciplines.\n"
      ],
      "metadata": {
        "id": "QKNIa1bEAqL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Familiar with CoLab\n",
        "Once you log into CoLab using your Gmail account and google drive, you would be able to play around with welcome notebook. The lecturer would introduce a few basics in the classroom.\n"
      ],
      "metadata": {
        "id": "gdmnz96nCgGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Executing Python Codes\n",
        "With Colab you can harness the full power of popular Python libraries to analyze and visualize data.\n",
        "\n",
        "Let us run a simple piece of python code to test in he code cell below.\n"
      ],
      "metadata": {
        "id": "QwNcHLsaMKX9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afBIhXC6Ae9N"
      },
      "outputs": [],
      "source": [
        "print(\"Hello, World!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you run this code, it will output the text Hello, World! to the console. This is a basic example often used to demonstrate the syntax for printing output in Python.\n",
        "\n",
        "## PySpark Testing\n",
        "In this section we will see how to install pyspark and test PySpark codes in a Google Colaboratory notebook.\n",
        "\n",
        "##  Install\n",
        "\n",
        "The first step involves installing pyspark.  The next step is to install findspark library.\n",
        "\n",
        "*Note: the --ignore-install flag is used to ignore previous installations and use the latest one built alongside the allocated cluster.*"
      ],
      "metadata": {
        "id": "qMMpy08yM4GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install pyspark using pip\n",
        "!pip install --ignore-install -q pyspark\n",
        "# install findspark using pip\n",
        "!pip install --ignore-install -q findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mwqRkIXNOnF",
        "outputId": "1df6c450-1dc0-4bff-f96e-16f44dd4dd74"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SparkSession\n",
        "We import the basic object SparkSession from the Spark Framework. In PySpark, a Spark Session is a unified entry point into the framework for reading data, configuring the system, and managing various Spark services.\n",
        "\n",
        "In PySpark, a Spark Session is created using the SparkSession.builder method. Here's an example:"
      ],
      "metadata": {
        "id": "n4mWRVMSNQo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# import collections\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"My First PySpark App\").getOrCreate()"
      ],
      "metadata": {
        "id": "AkNx3IhINolC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Mount a Local File into CoLab Folder\n",
        "\n",
        "Since a Colab notebook is hosted on Google's cloud servers, there's no direct access to files on your local drive (unlike a notebook hosted on your machine) or any other environment by default.\n",
        "\n",
        "You have to download the wordcount.txt from [git](https://github.com/suriarasai/BEAD2024/blob/main/colab/wordcount.txt) and upload the file to your colab files folder (look for folder icon).\n",
        "\n",
        "## Word Count\n",
        "\n",
        "For testing the pyspark codes we will load a text file and count the number of lines in side using the framework.\n",
        "\n",
        "Now let us try counting the number of lines in a given text file.\n",
        "\n",
        "To count the number of lines in a file using PySpark, you first need to initialize a Spark session and then read the file into a RDD (Resilient Distributed Dataset). After that, you can use actions like count() to get the number of lines.\n",
        "\n",
        "Then execute the below piece of code."
      ],
      "metadata": {
        "id": "pobbOqfYN08U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the file is named as wordcount.txt\n",
        "file_rdd = spark.sparkContext.textFile(\"wordcount.txt\")\n",
        "line_count = file_rdd.count()\n",
        "print(f\"Number of lines in the file: {line_count}\")"
      ],
      "metadata": {
        "id": "b86wWkyDO6Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a basic example and might need to be adjusted depending on your specific file format and the environment where you're running PySpark."
      ],
      "metadata": {
        "id": "-Y_39pircttB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0pQ05PGacvS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "You can use the drive module from google.colab to mount your entire Google Drive to Colab by:\n",
        "\n",
        "Executing the below code which will provide you with an authentication link to connect to Google Drive"
      ],
      "metadata": {
        "id": "2IRSmYajd0cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to read in data from a text file, first upload the data file into your google drive and then mount your google drive onto colab\n",
        "from google.colab import drive\n",
        "# to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True)\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "dmJkiFhrd2Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose the Google account whose Drive you want to mount. Allow Google Drive Stream access to your Google Account.\n",
        "\n",
        "Once the Drive is mounted, we will get the message “Mounted at /content/drive”, and will be able to browse through the contents of your drive from the file-explorer pane.\n",
        "\n",
        "Now you can interact with your Google Drive as if it was a folder in your Colab environment. Any changes to this folder will reflect directly in your Google Drive. You can read the files in your Google Drive as any other file.\n",
        "\n",
        "You can even write directly to Google Drive from Colab using the usual file/directory operations.\n",
        "\n",
        "## Mounting GitHub Notebook\n",
        "You can either clone an entire GitHub repository to your Colab environment or access individual files from their raw link."
      ],
      "metadata": {
        "id": "j0BNp4y-fd1J"
      }
    }
  ]
}